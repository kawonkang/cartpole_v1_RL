{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28563698",
   "metadata": {},
   "source": [
    "CartPole을 연속 행동으로 감싸서 SAC 학습\n",
    "\n",
    "같은 CartPole에 대해 PPO, DQN도 학습\n",
    "\n",
    "EvalCallback으로 평가 곡선 로그 남기고, 마지막에 비교 플롯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fd44c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== 학습 시작: SAC ====\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\vissim_rl\\Lib\\site-packages\\torch\\cuda\\__init__.py:287: UserWarning: \n",
      "NVIDIA GeForce RTX 5080 with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5080 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 25.8      |\n",
      "|    ep_rew_mean     | 25.8      |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 11        |\n",
      "|    time_elapsed    | 9         |\n",
      "|    total_timesteps | 103       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -0.755    |\n",
      "|    critic_loss     | 2.31      |\n",
      "|    ent_coef        | 1         |\n",
      "|    ent_coef_loss   | -0.000492 |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2         |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.1     |\n",
      "|    ep_rew_mean     | 26.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 209      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.86    |\n",
      "|    critic_loss     | 0.131    |\n",
      "|    ent_coef        | 0.968    |\n",
      "|    ent_coef_loss   | -0.0546  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 108      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.1     |\n",
      "|    ep_rew_mean     | 27.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 27       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 325      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.55    |\n",
      "|    critic_loss     | 0.14     |\n",
      "|    ent_coef        | 0.935    |\n",
      "|    ent_coef_loss   | -0.113   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 224      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.8     |\n",
      "|    ep_rew_mean     | 24.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 396      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.98    |\n",
      "|    critic_loss     | 0.158    |\n",
      "|    ent_coef        | 0.916    |\n",
      "|    ent_coef_loss   | -0.149   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 295      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.8     |\n",
      "|    ep_rew_mean     | 24.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 496      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.51    |\n",
      "|    critic_loss     | 0.286    |\n",
      "|    ent_coef        | 0.889    |\n",
      "|    ent_coef_loss   | -0.196   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 395      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.5     |\n",
      "|    ep_rew_mean     | 26.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 42       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 635      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.13    |\n",
      "|    critic_loss     | 0.688    |\n",
      "|    ent_coef        | 0.852    |\n",
      "|    ent_coef_loss   | -0.265   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 534      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26       |\n",
      "|    ep_rew_mean     | 26       |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 45       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 728      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.77    |\n",
      "|    critic_loss     | 0.643    |\n",
      "|    ent_coef        | 0.829    |\n",
      "|    ent_coef_loss   | -0.317   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 627      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26       |\n",
      "|    ep_rew_mean     | 26       |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 832      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.16    |\n",
      "|    critic_loss     | 0.425    |\n",
      "|    ent_coef        | 0.804    |\n",
      "|    ent_coef_loss   | -0.36    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 731      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25       |\n",
      "|    ep_rew_mean     | 25       |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 900      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.8     |\n",
      "|    critic_loss     | 1.23     |\n",
      "|    ent_coef        | 0.788    |\n",
      "|    ent_coef_loss   | -0.395   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 799      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.9     |\n",
      "|    ep_rew_mean     | 24.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 995      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.2     |\n",
      "|    critic_loss     | 0.235    |\n",
      "|    ent_coef        | 0.766    |\n",
      "|    ent_coef_loss   | -0.427   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 894      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.4     |\n",
      "|    ep_rew_mean     | 25.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 56       |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 1117     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.47    |\n",
      "|    critic_loss     | 0.51     |\n",
      "|    ent_coef        | 0.739    |\n",
      "|    ent_coef_loss   | -0.496   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1016     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.4     |\n",
      "|    ep_rew_mean     | 25.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 1221     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.25    |\n",
      "|    critic_loss     | 0.752    |\n",
      "|    ent_coef        | 0.716    |\n",
      "|    ent_coef_loss   | -0.519   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1120     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.7     |\n",
      "|    ep_rew_mean     | 26.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 1389     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.88    |\n",
      "|    critic_loss     | 0.866    |\n",
      "|    ent_coef        | 0.683    |\n",
      "|    ent_coef_loss   | -0.561   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1288     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.7     |\n",
      "|    ep_rew_mean     | 30.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 66       |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 1718     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.9    |\n",
      "|    critic_loss     | 1.38     |\n",
      "|    ent_coef        | 0.622    |\n",
      "|    ent_coef_loss   | -0.69    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1617     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.6     |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 70       |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 2079     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.8    |\n",
      "|    critic_loss     | 0.323    |\n",
      "|    ent_coef        | 0.564    |\n",
      "|    ent_coef_loss   | -0.81    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1978     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36.4     |\n",
      "|    ep_rew_mean     | 36.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 71       |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 2330     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.3    |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    ent_coef        | 0.527    |\n",
      "|    ent_coef_loss   | -1.05    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2229     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.2     |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 75       |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 2937     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.8    |\n",
      "|    critic_loss     | 0.359    |\n",
      "|    ent_coef        | 0.449    |\n",
      "|    ent_coef_loss   | -0.951   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2836     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50.8     |\n",
      "|    ep_rew_mean     | 50.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 3656     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.4    |\n",
      "|    critic_loss     | 0.568    |\n",
      "|    ent_coef        | 0.37     |\n",
      "|    ent_coef_loss   | -1.2     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3555     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 59       |\n",
      "|    ep_rew_mean     | 59       |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 4487     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 0.513    |\n",
      "|    ent_coef        | 0.296    |\n",
      "|    ent_coef_loss   | -1.16    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4386     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=228.60 +/- 40.40\n",
      "Episode length: 228.60 +/- 40.40\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 229      |\n",
      "|    mean_reward     | 229      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.6    |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    ent_coef        | 0.257    |\n",
      "|    ent_coef_loss   | -1.22    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 65.3     |\n",
      "|    ep_rew_mean     | 65.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 61       |\n",
      "|    total_timesteps | 5227     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 0.62     |\n",
      "|    ent_coef        | 0.24     |\n",
      "|    ent_coef_loss   | -1.52    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5126     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 70.5     |\n",
      "|    ep_rew_mean     | 70.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 5921     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.8    |\n",
      "|    critic_loss     | 0.237    |\n",
      "|    ent_coef        | 0.197    |\n",
      "|    ent_coef_loss   | -1.92    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5820     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.5     |\n",
      "|    ep_rew_mean     | 77.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 6822     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.4    |\n",
      "|    critic_loss     | 0.782    |\n",
      "|    ent_coef        | 0.153    |\n",
      "|    ent_coef_loss   | -1.82    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6721     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 82       |\n",
      "|    ep_rew_mean     | 82       |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 7546     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.5    |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    ent_coef        | 0.125    |\n",
      "|    ent_coef_loss   | -1.74    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7445     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 86.4     |\n",
      "|    ep_rew_mean     | 86.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 89       |\n",
      "|    total_timesteps | 8290     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -34.2    |\n",
      "|    critic_loss     | 0.294    |\n",
      "|    ent_coef        | 0.102    |\n",
      "|    ent_coef_loss   | -2.09    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8189     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 89.9     |\n",
      "|    ep_rew_mean     | 89.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 8994     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -35.9    |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    ent_coef        | 0.0842   |\n",
      "|    ent_coef_loss   | -2.08    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8893     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 96.3     |\n",
      "|    ep_rew_mean     | 96.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 102      |\n",
      "|    total_timesteps | 9738     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -38.6    |\n",
      "|    critic_loss     | 9.34     |\n",
      "|    ent_coef        | 0.0694   |\n",
      "|    ent_coef_loss   | -1.26    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9637     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=183.80 +/- 38.46\n",
      "Episode length: 183.80 +/- 38.46\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 184      |\n",
      "|    mean_reward     | 184      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -37.3    |\n",
      "|    critic_loss     | 0.342    |\n",
      "|    ent_coef        | 0.0647   |\n",
      "|    ent_coef_loss   | -1.25    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 10451    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -38.5    |\n",
      "|    critic_loss     | 0.769    |\n",
      "|    ent_coef        | 0.0575   |\n",
      "|    ent_coef_loss   | -2.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 10350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | 109      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 116      |\n",
      "|    total_timesteps | 11177    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -40.4    |\n",
      "|    critic_loss     | 1.79     |\n",
      "|    ent_coef        | 0.0475   |\n",
      "|    ent_coef_loss   | -1.98    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11076    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 116      |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 11970    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -42.3    |\n",
      "|    critic_loss     | 1.02     |\n",
      "|    ent_coef        | 0.0387   |\n",
      "|    ent_coef_loss   | -2.11    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 11869    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 123      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 97       |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 12787    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -44.3    |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    ent_coef        | 0.0323   |\n",
      "|    ent_coef_loss   | -1.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 12686    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 130      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 142      |\n",
      "|    total_timesteps | 13613    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -46.3    |\n",
      "|    critic_loss     | 0.853    |\n",
      "|    ent_coef        | 0.0294   |\n",
      "|    ent_coef_loss   | -0.213   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 13512    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 137      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 14426    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -45.2    |\n",
      "|    critic_loss     | 0.478    |\n",
      "|    ent_coef        | 0.0287   |\n",
      "|    ent_coef_loss   | -1.28    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14325    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=200.60 +/- 51.95\n",
      "Episode length: 200.60 +/- 51.95\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 201      |\n",
      "|    mean_reward     | 201      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -45.2    |\n",
      "|    critic_loss     | 0.325    |\n",
      "|    ent_coef        | 0.0287   |\n",
      "|    ent_coef_loss   | -1.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 14899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 143      |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 15117    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.1    |\n",
      "|    critic_loss     | 0.465    |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | -0.588   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15016    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 150      |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 173      |\n",
      "|    total_timesteps | 15908    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -51.2    |\n",
      "|    critic_loss     | 2.94     |\n",
      "|    ent_coef        | 0.0289   |\n",
      "|    ent_coef_loss   | 0.218    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15807    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 157      |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 16646    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -50.2    |\n",
      "|    critic_loss     | 0.26     |\n",
      "|    ent_coef        | 0.0254   |\n",
      "|    ent_coef_loss   | 0.681    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 16545    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 163      |\n",
      "|    ep_rew_mean     | 163      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 191      |\n",
      "|    total_timesteps | 17378    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.7    |\n",
      "|    critic_loss     | 0.523    |\n",
      "|    ent_coef        | 0.0224   |\n",
      "|    ent_coef_loss   | -1.77    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 17277    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 169      |\n",
      "|    ep_rew_mean     | 169      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 199      |\n",
      "|    total_timesteps | 18166    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.3    |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    ent_coef        | 0.0214   |\n",
      "|    ent_coef_loss   | -0.835   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18065    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 175      |\n",
      "|    ep_rew_mean     | 175      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 207      |\n",
      "|    total_timesteps | 18911    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.4    |\n",
      "|    critic_loss     | 1.4      |\n",
      "|    ent_coef        | 0.0178   |\n",
      "|    ent_coef_loss   | -0.7     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 18810    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | 179      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 19596    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.3    |\n",
      "|    critic_loss     | 0.88     |\n",
      "|    ent_coef        | 0.0169   |\n",
      "|    ent_coef_loss   | 0.623    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19495    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=211.90 +/- 29.67\n",
      "Episode length: 211.90 +/- 29.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 212      |\n",
      "|    mean_reward     | 212      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.8    |\n",
      "|    critic_loss     | 0.955    |\n",
      "|    ent_coef        | 0.0169   |\n",
      "|    ent_coef_loss   | 0.644    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 19899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 224      |\n",
      "|    total_timesteps | 20380    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.5    |\n",
      "|    critic_loss     | 0.294    |\n",
      "|    ent_coef        | 0.0164   |\n",
      "|    ent_coef_loss   | -0.444   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 20279    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 21102    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.7    |\n",
      "|    critic_loss     | 1.39     |\n",
      "|    ent_coef        | 0.0171   |\n",
      "|    ent_coef_loss   | -0.186   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21001    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 190      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 21942    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.9    |\n",
      "|    critic_loss     | 0.206    |\n",
      "|    ent_coef        | 0.0161   |\n",
      "|    ent_coef_loss   | -1.45    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 21841    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 189      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 244      |\n",
      "|    total_timesteps | 22579    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.2    |\n",
      "|    critic_loss     | 0.844    |\n",
      "|    ent_coef        | 0.0164   |\n",
      "|    ent_coef_loss   | 1.38     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 22478    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 23243    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.9    |\n",
      "|    critic_loss     | 0.647    |\n",
      "|    ent_coef        | 0.0168   |\n",
      "|    ent_coef_loss   | -0.181   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23142    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 187      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 23939    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.5    |\n",
      "|    critic_loss     | 0.562    |\n",
      "|    ent_coef        | 0.017    |\n",
      "|    ent_coef_loss   | -0.708   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 23838    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 188      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 24695    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.6    |\n",
      "|    critic_loss     | 0.989    |\n",
      "|    ent_coef        | 0.0158   |\n",
      "|    ent_coef_loss   | 0.59     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24594    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=162.40 +/- 18.47\n",
      "Episode length: 162.40 +/- 18.47\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 162      |\n",
      "|    mean_reward     | 162      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 25000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.5    |\n",
      "|    critic_loss     | 0.21     |\n",
      "|    ent_coef        | 0.0158   |\n",
      "|    ent_coef_loss   | -0.97    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 185      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 270      |\n",
      "|    total_timesteps | 25319    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -52.9    |\n",
      "|    critic_loss     | 0.963    |\n",
      "|    ent_coef        | 0.0165   |\n",
      "|    ent_coef_loss   | 1.21     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25218    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 184      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 25988    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.6    |\n",
      "|    critic_loss     | 1.83     |\n",
      "|    ent_coef        | 0.0177   |\n",
      "|    ent_coef_loss   | 1.87     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 25887    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 26609    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.7    |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    ent_coef        | 0.0188   |\n",
      "|    ent_coef_loss   | -2.56    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 26508    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 27317    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.8    |\n",
      "|    critic_loss     | 0.874    |\n",
      "|    ent_coef        | 0.0211   |\n",
      "|    ent_coef_loss   | 1.51     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27216    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 182      |\n",
      "|    ep_rew_mean     | 182      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 27988    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56.8    |\n",
      "|    critic_loss     | 0.293    |\n",
      "|    ent_coef        | 0.0226   |\n",
      "|    ent_coef_loss   | 0.537    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 27887    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 182      |\n",
      "|    ep_rew_mean     | 182      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 299      |\n",
      "|    total_timesteps | 28649    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56.8    |\n",
      "|    critic_loss     | 0.649    |\n",
      "|    ent_coef        | 0.0247   |\n",
      "|    ent_coef_loss   | -0.119   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 28548    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 181      |\n",
      "|    ep_rew_mean     | 181      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 305      |\n",
      "|    total_timesteps | 29268    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57      |\n",
      "|    critic_loss     | 0.287    |\n",
      "|    ent_coef        | 0.026    |\n",
      "|    ent_coef_loss   | -0.0857  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29167    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 311      |\n",
      "|    total_timesteps | 29984    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.4    |\n",
      "|    critic_loss     | 0.252    |\n",
      "|    ent_coef        | 0.0272   |\n",
      "|    ent_coef_loss   | -0.451   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29883    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=215.70 +/- 38.45\n",
      "Episode length: 215.70 +/- 38.45\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 216      |\n",
      "|    mean_reward     | 216      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.9    |\n",
      "|    critic_loss     | 0.65     |\n",
      "|    ent_coef        | 0.0273   |\n",
      "|    ent_coef_loss   | 1.61     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 29899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 30823    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.2    |\n",
      "|    critic_loss     | 0.246    |\n",
      "|    ent_coef        | 0.0318   |\n",
      "|    ent_coef_loss   | -0.533   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 30722    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 181      |\n",
      "|    ep_rew_mean     | 181      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 335      |\n",
      "|    total_timesteps | 31690    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.3    |\n",
      "|    critic_loss     | 5.2      |\n",
      "|    ent_coef        | 0.0318   |\n",
      "|    ent_coef_loss   | 0.856    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 31589    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 345      |\n",
      "|    total_timesteps | 32443    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.7    |\n",
      "|    critic_loss     | 0.352    |\n",
      "|    ent_coef        | 0.027    |\n",
      "|    ent_coef_loss   | -0.65    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 32342    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 353      |\n",
      "|    total_timesteps | 33123    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57.2    |\n",
      "|    critic_loss     | 9.72     |\n",
      "|    ent_coef        | 0.0228   |\n",
      "|    ent_coef_loss   | 0.788    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33022    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | 179      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 362      |\n",
      "|    total_timesteps | 33779    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.7    |\n",
      "|    critic_loss     | 1.97     |\n",
      "|    ent_coef        | 0.0218   |\n",
      "|    ent_coef_loss   | -1.19    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 33678    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 178      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 370      |\n",
      "|    total_timesteps | 34428    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.8    |\n",
      "|    critic_loss     | 0.917    |\n",
      "|    ent_coef        | 0.0196   |\n",
      "|    ent_coef_loss   | -0.137   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34327    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=180.00 +/- 11.12\n",
      "Episode length: 180.00 +/- 11.12\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 180      |\n",
      "|    mean_reward     | 180      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.4    |\n",
      "|    critic_loss     | 0.71     |\n",
      "|    ent_coef        | 0.0198   |\n",
      "|    ent_coef_loss   | 1.44     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 34899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 178      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 380      |\n",
      "|    total_timesteps | 35172    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.7    |\n",
      "|    critic_loss     | 0.457    |\n",
      "|    ent_coef        | 0.0201   |\n",
      "|    ent_coef_loss   | 0.0479   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35071    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 178      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 388      |\n",
      "|    total_timesteps | 35949    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.3    |\n",
      "|    critic_loss     | 0.182    |\n",
      "|    ent_coef        | 0.0224   |\n",
      "|    ent_coef_loss   | -0.674   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 35848    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 178      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 397      |\n",
      "|    total_timesteps | 36709    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.7    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    ent_coef        | 0.0234   |\n",
      "|    ent_coef_loss   | 0.934    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 36608    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 405      |\n",
      "|    total_timesteps | 37577    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -49.8    |\n",
      "|    critic_loss     | 0.115    |\n",
      "|    ent_coef        | 0.0279   |\n",
      "|    ent_coef_loss   | 0.826    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 37476    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 413      |\n",
      "|    total_timesteps | 38425    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.3    |\n",
      "|    critic_loss     | 3.73     |\n",
      "|    ent_coef        | 0.0285   |\n",
      "|    ent_coef_loss   | 1.2      |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 38324    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 184      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 422      |\n",
      "|    total_timesteps | 39460    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.7    |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.0296   |\n",
      "|    ent_coef_loss   | -0.831   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39359    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=236.10 +/- 28.00\n",
      "Episode length: 236.10 +/- 28.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 236      |\n",
      "|    mean_reward     | 236      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 40000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.1    |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | -0.909   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 39899    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 185      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 40425    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.8    |\n",
      "|    critic_loss     | 0.208    |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | 0.277    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 40324    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 187      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 441      |\n",
      "|    total_timesteps | 41280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.1    |\n",
      "|    critic_loss     | 0.362    |\n",
      "|    ent_coef        | 0.0277   |\n",
      "|    ent_coef_loss   | 0.548    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 41179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 190      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 449      |\n",
      "|    total_timesteps | 42200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -54.3    |\n",
      "|    critic_loss     | 0.276    |\n",
      "|    ent_coef        | 0.0265   |\n",
      "|    ent_coef_loss   | 0.281    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 42099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 194      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 460      |\n",
      "|    total_timesteps | 43342    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -57      |\n",
      "|    critic_loss     | 0.72     |\n",
      "|    ent_coef        | 0.0282   |\n",
      "|    ent_coef_loss   | 0.748    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 43241    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 196      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 469      |\n",
      "|    total_timesteps | 44307    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.5    |\n",
      "|    critic_loss     | 0.165    |\n",
      "|    ent_coef        | 0.0279   |\n",
      "|    ent_coef_loss   | 0.537    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44206    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=231.00 +/- 15.22\n",
      "Episode length: 231.00 +/- 15.22\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 231      |\n",
      "|    mean_reward     | 231      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 45000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.9    |\n",
      "|    critic_loss     | 0.245    |\n",
      "|    ent_coef        | 0.0266   |\n",
      "|    ent_coef_loss   | -0.784   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 44899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 200      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 479      |\n",
      "|    total_timesteps | 45271    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.5    |\n",
      "|    critic_loss     | 1.47     |\n",
      "|    ent_coef        | 0.0264   |\n",
      "|    ent_coef_loss   | 0.127    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 45170    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | 202      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 487      |\n",
      "|    total_timesteps | 46188    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -60.6    |\n",
      "|    critic_loss     | 0.11     |\n",
      "|    ent_coef        | 0.0269   |\n",
      "|    ent_coef_loss   | 0.606    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 46087    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 205      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 498      |\n",
      "|    total_timesteps | 47075    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -56.3    |\n",
      "|    critic_loss     | 0.287    |\n",
      "|    ent_coef        | 0.0237   |\n",
      "|    ent_coef_loss   | 0.346    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 46974    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 210      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 48310    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.2    |\n",
      "|    critic_loss     | 0.89     |\n",
      "|    ent_coef        | 0.0238   |\n",
      "|    ent_coef_loss   | -1.64    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 48209    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 215      |\n",
      "|    ep_rew_mean     | 215      |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 528      |\n",
      "|    total_timesteps | 49440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -53.9    |\n",
      "|    critic_loss     | 0.418    |\n",
      "|    ent_coef        | 0.0246   |\n",
      "|    ent_coef_loss   | -0.0629  |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 49339    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=321.20 +/- 45.67\n",
      "Episode length: 321.20 +/- 45.67\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 321      |\n",
      "|    mean_reward     | 321      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 50000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58      |\n",
      "|    critic_loss     | 0.107    |\n",
      "|    ent_coef        | 0.0254   |\n",
      "|    ent_coef_loss   | 0.759    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 49899    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 222      |\n",
      "|    ep_rew_mean     | 222      |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 548      |\n",
      "|    total_timesteps | 50898    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.1    |\n",
      "|    critic_loss     | 0.464    |\n",
      "|    ent_coef        | 0.0311   |\n",
      "|    ent_coef_loss   | 1.22     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50797    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 565      |\n",
      "|    total_timesteps | 52585    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.8    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    ent_coef        | 0.0316   |\n",
      "|    ent_coef_loss   | 0.434    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 52484    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 581      |\n",
      "|    total_timesteps | 54080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -61.6    |\n",
      "|    critic_loss     | 0.147    |\n",
      "|    ent_coef        | 0.0332   |\n",
      "|    ent_coef_loss   | -1.04    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 53979    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=290.00 +/- 38.25\n",
      "Episode length: 290.00 +/- 38.25\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 290      |\n",
      "|    mean_reward     | 290      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 55000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.5    |\n",
      "|    critic_loss     | 0.541    |\n",
      "|    ent_coef        | 0.031    |\n",
      "|    ent_coef_loss   | -0.965   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 54899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 245      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 594      |\n",
      "|    total_timesteps | 55321    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -55.5    |\n",
      "|    critic_loss     | 0.139    |\n",
      "|    ent_coef        | 0.0294   |\n",
      "|    ent_coef_loss   | -0.355   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 55220    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 611      |\n",
      "|    total_timesteps | 57145    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -62.6    |\n",
      "|    critic_loss     | 0.11     |\n",
      "|    ent_coef        | 0.0319   |\n",
      "|    ent_coef_loss   | 0.356    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 57044    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 266      |\n",
      "|    ep_rew_mean     | 266      |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 628      |\n",
      "|    total_timesteps | 59078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -59.2    |\n",
      "|    critic_loss     | 0.247    |\n",
      "|    ent_coef        | 0.0269   |\n",
      "|    ent_coef_loss   | -0.61    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 58977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 60000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65      |\n",
      "|    critic_loss     | 0.201    |\n",
      "|    ent_coef        | 0.0256   |\n",
      "|    ent_coef_loss   | 0.116    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 59899    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 280      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 649      |\n",
      "|    total_timesteps | 61078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63      |\n",
      "|    critic_loss     | 0.227    |\n",
      "|    ent_coef        | 0.0273   |\n",
      "|    ent_coef_loss   | -0.228   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 60977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 293      |\n",
      "|    ep_rew_mean     | 293      |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 94       |\n",
      "|    time_elapsed    | 667      |\n",
      "|    total_timesteps | 63078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.4    |\n",
      "|    critic_loss     | 0.169    |\n",
      "|    ent_coef        | 0.029    |\n",
      "|    ent_coef_loss   | -0.879   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 62977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 65000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -58.2    |\n",
      "|    critic_loss     | 0.652    |\n",
      "|    ent_coef        | 0.0346   |\n",
      "|    ent_coef_loss   | 1.56     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 306      |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 694      |\n",
      "|    total_timesteps | 65078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63      |\n",
      "|    critic_loss     | 0.167    |\n",
      "|    ent_coef        | 0.0355   |\n",
      "|    ent_coef_loss   | 1.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 64977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | 319      |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 719      |\n",
      "|    total_timesteps | 67078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -63.5    |\n",
      "|    critic_loss     | 0.67     |\n",
      "|    ent_coef        | 0.0359   |\n",
      "|    ent_coef_loss   | -0.714   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 66977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 331      |\n",
      "|    ep_rew_mean     | 331      |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 743      |\n",
      "|    total_timesteps | 69078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -65.7    |\n",
      "|    critic_loss     | 0.126    |\n",
      "|    ent_coef        | 0.0386   |\n",
      "|    ent_coef_loss   | -0.342   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 68977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 70000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -72.2    |\n",
      "|    critic_loss     | 0.0974   |\n",
      "|    ent_coef        | 0.0383   |\n",
      "|    ent_coef_loss   | 0.201    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 69899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 344      |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 769      |\n",
      "|    total_timesteps | 71078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -68.6    |\n",
      "|    critic_loss     | 0.0662   |\n",
      "|    ent_coef        | 0.0411   |\n",
      "|    ent_coef_loss   | 0.81     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 70977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 355      |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 789      |\n",
      "|    total_timesteps | 73078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -71.3    |\n",
      "|    critic_loss     | 2.13     |\n",
      "|    ent_coef        | 0.0428   |\n",
      "|    ent_coef_loss   | 0.413    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 72977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 75000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -74.8    |\n",
      "|    critic_loss     | 0.612    |\n",
      "|    ent_coef        | 0.0357   |\n",
      "|    ent_coef_loss   | -0.245   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 74899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 367      |\n",
      "|    ep_rew_mean     | 367      |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 810      |\n",
      "|    total_timesteps | 75078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -66.7    |\n",
      "|    critic_loss     | 0.199    |\n",
      "|    ent_coef        | 0.036    |\n",
      "|    ent_coef_loss   | 1.21     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 74977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 376      |\n",
      "|    ep_rew_mean     | 376      |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 828      |\n",
      "|    total_timesteps | 77078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.1    |\n",
      "|    critic_loss     | 0.7      |\n",
      "|    ent_coef        | 0.0321   |\n",
      "|    ent_coef_loss   | -1.3     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 76977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 387      |\n",
      "|    ep_rew_mean     | 387      |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 845      |\n",
      "|    total_timesteps | 79078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -74.4    |\n",
      "|    critic_loss     | 0.385    |\n",
      "|    ent_coef        | 0.0319   |\n",
      "|    ent_coef_loss   | -0.00626 |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 78977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 80000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78.8    |\n",
      "|    critic_loss     | 0.155    |\n",
      "|    ent_coef        | 0.0347   |\n",
      "|    ent_coef_loss   | 0.771    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 79899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 398      |\n",
      "|    ep_rew_mean     | 398      |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 872      |\n",
      "|    total_timesteps | 81078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.2    |\n",
      "|    critic_loss     | 0.227    |\n",
      "|    ent_coef        | 0.042    |\n",
      "|    ent_coef_loss   | -0.128   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 80977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 409      |\n",
      "|    ep_rew_mean     | 409      |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 896      |\n",
      "|    total_timesteps | 83078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -76.7    |\n",
      "|    critic_loss     | 0.103    |\n",
      "|    ent_coef        | 0.0416   |\n",
      "|    ent_coef_loss   | 1.68     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 82977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 85000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -84.3    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    ent_coef        | 0.0403   |\n",
      "|    ent_coef_loss   | -0.324   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 84899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 417      |\n",
      "|    ep_rew_mean     | 417      |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 925      |\n",
      "|    total_timesteps | 85078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -80.8    |\n",
      "|    critic_loss     | 0.125    |\n",
      "|    ent_coef        | 0.0406   |\n",
      "|    ent_coef_loss   | 0.934    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 84977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 428      |\n",
      "|    ep_rew_mean     | 428      |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 948      |\n",
      "|    total_timesteps | 87078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -73.2    |\n",
      "|    critic_loss     | 0.154    |\n",
      "|    ent_coef        | 0.0354   |\n",
      "|    ent_coef_loss   | 1.11     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 86977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 438      |\n",
      "|    ep_rew_mean     | 438      |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 968      |\n",
      "|    total_timesteps | 89078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.6    |\n",
      "|    critic_loss     | 0.35     |\n",
      "|    ent_coef        | 0.0299   |\n",
      "|    ent_coef_loss   | -0.845   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 88977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 90000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -78      |\n",
      "|    critic_loss     | 0.0793   |\n",
      "|    ent_coef        | 0.0324   |\n",
      "|    ent_coef_loss   | 0.632    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 89899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 449      |\n",
      "|    ep_rew_mean     | 449      |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 990      |\n",
      "|    total_timesteps | 91078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.9    |\n",
      "|    critic_loss     | 0.0516   |\n",
      "|    ent_coef        | 0.0327   |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 90977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 460      |\n",
      "|    ep_rew_mean     | 460      |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 1009     |\n",
      "|    total_timesteps | 93078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.5    |\n",
      "|    critic_loss     | 0.176    |\n",
      "|    ent_coef        | 0.0349   |\n",
      "|    ent_coef_loss   | -0.463   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 92977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 95000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.7    |\n",
      "|    critic_loss     | 0.0992   |\n",
      "|    ent_coef        | 0.0328   |\n",
      "|    ent_coef_loss   | 0.61     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 468      |\n",
      "|    ep_rew_mean     | 468      |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 1032     |\n",
      "|    total_timesteps | 95078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -81.7    |\n",
      "|    critic_loss     | 0.0964   |\n",
      "|    ent_coef        | 0.0337   |\n",
      "|    ent_coef_loss   | 0.988    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 94977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 476      |\n",
      "|    ep_rew_mean     | 476      |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 1057     |\n",
      "|    total_timesteps | 97078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -79.4    |\n",
      "|    critic_loss     | 0.0843   |\n",
      "|    ent_coef        | 0.0268   |\n",
      "|    ent_coef_loss   | -0.383   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 96977    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | 482      |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 1082     |\n",
      "|    total_timesteps | 99078    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -77.2    |\n",
      "|    critic_loss     | 0.142    |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | 1.09     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 98977    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 500      |\n",
      "|    mean_reward     | 500      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 100000   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -82.4    |\n",
      "|    critic_loss     | 0.078    |\n",
      "|    ent_coef        | 0.0284   |\n",
      "|    ent_coef_loss   | 1.35     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 99899    |\n",
      "---------------------------------\n",
      "[SAC] 최종 평가: mean_reward=500.00, std=0.00\n",
      "\n",
      "==== 학습 시작: PPO ====\n",
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\vissim_rl\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | 22.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 29         |\n",
      "|    ep_rew_mean          | 29         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 81         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 50         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00899988 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.00607    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.35       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 51.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=101.90 +/- 25.93\n",
      "Episode length: 101.90 +/- 25.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 102         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5000        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007316828 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.6     |\n",
      "|    ep_rew_mean     | 34.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 112      |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.5        |\n",
      "|    ep_rew_mean          | 45.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006926774 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=282.10 +/- 134.69\n",
      "Episode length: 282.10 +/- 134.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 282        |\n",
      "|    mean_reward          | 282        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 10000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01140541 |\n",
      "|    clip_fraction        | 0.0982     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.604     |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    value_loss           | 63.2       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 57.2     |\n",
      "|    ep_rew_mean     | 57.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 161      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.5        |\n",
      "|    ep_rew_mean          | 71.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 183         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004998031 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 87.9        |\n",
      "|    ep_rew_mean          | 87.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 203         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008962635 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 52.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=408.20 +/- 94.93\n",
      "Episode length: 408.20 +/- 94.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 408         |\n",
      "|    mean_reward          | 408         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007607611 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    value_loss           | 52          |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | 107      |\n",
      "| time/              |          |\n",
      "|    fps             | 213      |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 16384    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 123         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 229         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009743577 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=473.40 +/- 32.87\n",
      "Episode length: 473.40 +/- 32.87\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 473        |\n",
      "|    mean_reward          | 473        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00679047 |\n",
      "|    clip_fraction        | 0.0572     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.574     |\n",
      "|    explained_variance   | 0.648      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.9       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00367   |\n",
      "|    value_loss           | 55.6       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 141      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    fps             | 236      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 86       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 161         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 249         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009028985 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.53        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 47.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 177         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007761409 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 13          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006182661 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 4.75        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 195      |\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 100      |\n",
      "|    total_timesteps | 26624    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 213          |\n",
      "|    ep_rew_mean          | 213          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 275          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 104          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027554836 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | -0.00537     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.41         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 27           |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046828957 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | -0.00866     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 63           |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 27.3         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 230      |\n",
      "|    ep_rew_mean     | 230      |\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 248         |\n",
      "|    ep_rew_mean          | 248         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012510733 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | -0.128      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 265         |\n",
      "|    ep_rew_mean          | 265         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002364195 |\n",
      "|    clip_fraction        | 0.00239     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 500           |\n",
      "|    mean_reward          | 500           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 35000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072618213 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.562        |\n",
      "|    explained_variance   | 0.827         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.234         |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000555     |\n",
      "|    value_loss           | 4.38          |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 281      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 130      |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 298          |\n",
      "|    ep_rew_mean          | 298          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 288          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060949996 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.554       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.33         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 2.33         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010891451 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00565    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.268       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 314      |\n",
      "|    ep_rew_mean     | 314      |\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 331          |\n",
      "|    ep_rew_mean          | 331          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 290          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032144147 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0132       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 0.133        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020648204 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0316       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00753      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 0.0803       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 348      |\n",
      "|    ep_rew_mean     | 348      |\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 156      |\n",
      "|    total_timesteps | 45056    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | 364         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004839259 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0495      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    value_loss           | 0.0541      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 379          |\n",
      "|    ep_rew_mean          | 379          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 295          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044519273 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | -0.046       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00621      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -6.5e-05     |\n",
      "|    value_loss           | 0.0331       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004798905 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0105      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00597     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 396      |\n",
      "|    ep_rew_mean     | 396      |\n",
      "| time/              |          |\n",
      "|    fps             | 293      |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 411          |\n",
      "|    ep_rew_mean          | 411          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 297          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032525577 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.00941      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00893     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 0.0144       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006401199 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | -0.0688     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00314     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 0.0094      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 425      |\n",
      "|    ep_rew_mean     | 425      |\n",
      "| time/              |          |\n",
      "|    fps             | 296      |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 186      |\n",
      "|    total_timesteps | 55296    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 437          |\n",
      "|    ep_rew_mean          | 437          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 300          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059609436 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | -0.00926     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0118      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 0.00596      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 448         |\n",
      "|    ep_rew_mean          | 448         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007469769 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0906      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 0.00413     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040533673 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | -0.0143      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00558      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 0.00267      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 458      |\n",
      "|    ep_rew_mean     | 458      |\n",
      "| time/              |          |\n",
      "|    fps             | 304      |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 468          |\n",
      "|    ep_rew_mean          | 468          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 309          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 205          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031599207 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0357       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00451     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    value_loss           | 0.00179      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041058036 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0679       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00879     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 0.00122      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 475      |\n",
      "|    ep_rew_mean     | 475      |\n",
      "| time/              |          |\n",
      "|    fps             | 308      |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 212      |\n",
      "|    total_timesteps | 65536    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 483          |\n",
      "|    ep_rew_mean          | 483          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 312          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 216          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026102639 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | -0.0298      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00341      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000665    |\n",
      "|    value_loss           | 0.000838     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 489         |\n",
      "|    ep_rew_mean          | 489         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005356648 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | -0.00646    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00176     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00047    |\n",
      "|    value_loss           | 0.00058     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032366244 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0706       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0167      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    value_loss           | 0.000412     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 492      |\n",
      "|    ep_rew_mean     | 492      |\n",
      "| time/              |          |\n",
      "|    fps             | 315      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 226      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 492         |\n",
      "|    ep_rew_mean          | 492         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 319         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004439119 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0085      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 0.000275    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008537844 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.0738      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    value_loss           | 0.000214    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 492      |\n",
      "|    ep_rew_mean     | 492      |\n",
      "| time/              |          |\n",
      "|    fps             | 319      |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 75776    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 492         |\n",
      "|    ep_rew_mean          | 492         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001810925 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000305    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.000486   |\n",
      "|    value_loss           | 0.000154    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 496         |\n",
      "|    ep_rew_mean          | 496         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 327         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004713958 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | -0.106      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000804   |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056113703 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0143       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0237      |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 8.48e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 497      |\n",
      "|    ep_rew_mean     | 497      |\n",
      "| time/              |          |\n",
      "|    fps             | 326      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 250      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 330         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004160733 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | -0.0135     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00484     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 4.3e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014233319 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | -0.187       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0168      |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.000793    |\n",
      "|    value_loss           | 3.41e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 500      |\n",
      "| time/              |          |\n",
      "|    fps             | 329      |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 86016    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | 500         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001787637 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.409      |\n",
      "|    explained_variance   | -0.0153     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00416    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 2.48e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042036595 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | -0.1         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00953      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.000948     |\n",
      "|    value_loss           | 2.31e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 500      |\n",
      "| time/              |          |\n",
      "|    fps             | 332      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 500          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024883184 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | -0.21        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00162     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000574    |\n",
      "|    value_loss           | 1.33e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 500          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 338          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 278          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057561044 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | -0.0488      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0128       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 9.71e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 500          |\n",
      "|    mean_reward          | 500          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 95000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015688734 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.354       |\n",
      "|    explained_variance   | -0.317       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    value_loss           | 7.44e-06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 500      |\n",
      "| time/              |          |\n",
      "|    fps             | 337      |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 96256    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | 500          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 340          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 288          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019460453 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | -0.105       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000103    |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 4.76e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=500.00 +/- 0.00\n",
      "Episode length: 500.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 500         |\n",
      "|    mean_reward          | 500         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004041373 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.321      |\n",
      "|    explained_variance   | -0.343      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 4.61e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 500      |\n",
      "|    ep_rew_mean     | 500      |\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "[PPO] 최종 평가: mean_reward=500.00, std=0.00\n",
      "\n",
      "==== 학습 시작: DQN ====\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 22403    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 94       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 25042    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 155      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 17828    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 270      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 18588    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 333      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 16613    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 410      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 17012    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 472      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.7     |\n",
      "|    ep_rew_mean      | 19.7     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 17576    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 551      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.3     |\n",
      "|    ep_rew_mean      | 19.3     |\n",
      "|    exploration_rate | 0.941    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 17987    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 618      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 18209    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 683      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 18038    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.916    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 17815    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 882      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 17078    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 948      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 10196    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1053     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 13       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.892    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 6735     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1140     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 34       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 5185     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1203     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 50       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.875    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 3839     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1312     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 77       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.867    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 3353     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1396     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00172  |\n",
      "|    n_updates        | 98       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 3247     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1440     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000592 |\n",
      "|    n_updates        | 109      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21       |\n",
      "|    ep_rew_mean      | 21       |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 2811     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1599     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000354 |\n",
      "|    n_updates        | 149      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2564     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1708     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000436 |\n",
      "|    n_updates        | 176      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 2448     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1771     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000329 |\n",
      "|    n_updates        | 192      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.825    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 2328     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1838     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000243 |\n",
      "|    n_updates        | 209      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 2289     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1893     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000324 |\n",
      "|    n_updates        | 223      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 2245     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1973     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.000262 |\n",
      "|    n_updates        | 243      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.3     |\n",
      "|    ep_rew_mean      | 20.3     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 2193     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2034     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0877   |\n",
      "|    n_updates        | 258      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 2135     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2081     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0634   |\n",
      "|    n_updates        | 270      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.795    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 2066     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2160     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 289      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 2012     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2218     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 304      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.4     |\n",
      "|    ep_rew_mean      | 19.4     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1966     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2271     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 317      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.5     |\n",
      "|    ep_rew_mean      | 19.5     |\n",
      "|    exploration_rate | 0.776    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1905     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2363     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 340      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.6     |\n",
      "|    ep_rew_mean      | 19.6     |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 1861     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2434     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 358      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 1820     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2534     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 383      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 1775     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2615     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 403      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20       |\n",
      "|    ep_rew_mean      | 20       |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 1749     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2685     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 421      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.9     |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.74     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 1733     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2741     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 435      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 1718     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2797     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 449      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19       |\n",
      "|    ep_rew_mean      | 19       |\n",
      "|    exploration_rate | 0.729    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 1708     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2852     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 462      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.5     |\n",
      "|    ep_rew_mean      | 18.5     |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 1707     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2903     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.009    |\n",
      "|    n_updates        | 475      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.2     |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 1703     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 2963     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 490      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.3     |\n",
      "|    ep_rew_mean      | 18.3     |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 1700     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3036     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0871   |\n",
      "|    n_updates        | 508      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.1     |\n",
      "|    ep_rew_mean      | 18.1     |\n",
      "|    exploration_rate | 0.704    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 1679     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3121     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 530      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.9     |\n",
      "|    ep_rew_mean      | 17.9     |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 1671     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3191     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 547      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18       |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 1655     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3241     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 560      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.1     |\n",
      "|    ep_rew_mean      | 17.1     |\n",
      "|    exploration_rate | 0.686    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 1644     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3304     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 575      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.8     |\n",
      "|    ep_rew_mean      | 16.8     |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 1636     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3392     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 597      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 16.9     |\n",
      "|    ep_rew_mean      | 16.9     |\n",
      "|    exploration_rate | 0.671    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 1615     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3465     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0564   |\n",
      "|    n_updates        | 616      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17.2     |\n",
      "|    ep_rew_mean      | 17.2     |\n",
      "|    exploration_rate | 0.662    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 1602     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3554     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 638      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.4     |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 1602     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3731     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0596   |\n",
      "|    n_updates        | 682      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.7     |\n",
      "|    ep_rew_mean      | 18.7     |\n",
      "|    exploration_rate | 0.635    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 1584     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3840     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 709      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 18.9     |\n",
      "|    ep_rew_mean      | 18.9     |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 1579     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 3927     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0435   |\n",
      "|    n_updates        | 731      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.2     |\n",
      "|    ep_rew_mean      | 19.2     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 1575     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0665   |\n",
      "|    n_updates        | 749      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 1571     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4068     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 766      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.1     |\n",
      "|    ep_rew_mean      | 19.1     |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 1559     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4124     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 780      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 19.8     |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.596    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 1535     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4255     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0549   |\n",
      "|    n_updates        | 813      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.585    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 1524     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4372     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 842      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 1515     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 4520     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 879      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 1501     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4651     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 912      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.3     |\n",
      "|    ep_rew_mean      | 21.3     |\n",
      "|    exploration_rate | 0.549    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 1490     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4749     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 937      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 1464     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4858     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0483   |\n",
      "|    n_updates        | 964      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 1456     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 4979     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0981   |\n",
      "|    n_updates        | 994      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=21.80 +/- 3.09\n",
      "Episode length: 21.80 +/- 3.09\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 21.8     |\n",
      "|    mean_reward      | 21.8     |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.525    |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 999      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 1409     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 5073     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 1018     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.492    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 1386     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 5349     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0672   |\n",
      "|    n_updates        | 1087     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 30.6     |\n",
      "|    ep_rew_mean      | 30.6     |\n",
      "|    exploration_rate | 0.434    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 1347     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 5962     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0974   |\n",
      "|    n_updates        | 1240     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.6     |\n",
      "|    ep_rew_mean      | 33.6     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 1327     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 6322     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 1330     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | 40.3     |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 1295     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 7069     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 1517     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.3     |\n",
      "|    ep_rew_mean      | 44.3     |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 1275     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 7549     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0993   |\n",
      "|    n_updates        | 1637     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.8     |\n",
      "|    ep_rew_mean      | 49.8     |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 1253     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 8166     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 1791     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 1222     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 8920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 1979     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=231.70 +/- 26.89\n",
      "Episode length: 231.70 +/- 26.89\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 232      |\n",
      "|    mean_reward      | 232      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.0501   |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 2249     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 1030     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 10040    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 2259     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75       |\n",
      "|    ep_rew_mean      | 75       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 1006     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 10890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0499   |\n",
      "|    n_updates        | 2472     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 84.4     |\n",
      "|    ep_rew_mean      | 84.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 987      |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 11905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0564   |\n",
      "|    n_updates        | 2726     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 96       |\n",
      "|    ep_rew_mean      | 96       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 962      |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 13152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0891   |\n",
      "|    n_updates        | 3037     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 949      |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 14481    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.322    |\n",
      "|    n_updates        | 3370     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=257.50 +/- 68.72\n",
      "Episode length: 257.50 +/- 68.72\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 258      |\n",
      "|    mean_reward      | 258      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 15000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.375    |\n",
      "|    n_updates        | 3499     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 15498    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 3624     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 16337    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 3834     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 901      |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 16954    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 3988     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | 135      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 902      |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 17603    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 4150     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 141      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 18232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 4307     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | 146      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 904      |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 18895    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.484    |\n",
      "|    n_updates        | 4473     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 151      |\n",
      "|    ep_rew_mean      | 151      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 903      |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 19491    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.704    |\n",
      "|    n_updates        | 4622     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=158.30 +/- 15.41\n",
      "Episode length: 158.30 +/- 15.41\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 158      |\n",
      "|    mean_reward      | 158      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 20000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 4749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 156      |\n",
      "|    ep_rew_mean      | 156      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 20127    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 4781     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 162      |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 866      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 20844    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0161   |\n",
      "|    n_updates        | 4960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 166      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 21398    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 5099     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 172      |\n",
      "|    ep_rew_mean      | 172      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 22017    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0823   |\n",
      "|    n_updates        | 5254     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 177      |\n",
      "|    ep_rew_mean      | 177      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 861      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 22687    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.559    |\n",
      "|    n_updates        | 5421     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 184      |\n",
      "|    ep_rew_mean      | 184      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 23496    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 5623     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 191      |\n",
      "|    ep_rew_mean      | 191      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 864      |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 24447    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 5861     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=25000, episode_reward=182.80 +/- 44.37\n",
      "Episode length: 182.80 +/- 44.37\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 183      |\n",
      "|    mean_reward      | 183      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 25000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 5999     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 191      |\n",
      "|    ep_rew_mean      | 191      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 25096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 6023     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 194      |\n",
      "|    ep_rew_mean      | 194      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 849      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 25751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00945  |\n",
      "|    n_updates        | 6187     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 196      |\n",
      "|    ep_rew_mean      | 196      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 26651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 6412     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 198      |\n",
      "|    ep_rew_mean      | 198      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 27343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0838   |\n",
      "|    n_updates        | 6585     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 201      |\n",
      "|    ep_rew_mean      | 201      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 28226    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 6806     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 202      |\n",
      "|    ep_rew_mean      | 202      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 861      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 29110    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.285    |\n",
      "|    n_updates        | 7027     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 199      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 860      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 29897    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 7224     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=286.60 +/- 74.23\n",
      "Episode length: 286.60 +/- 74.23\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 287      |\n",
      "|    mean_reward      | 287      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 30000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 7249     |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 200      |\n",
      "|    ep_rew_mean      | 200      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 30884    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.368    |\n",
      "|    n_updates        | 7470     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 199      |\n",
      "|    ep_rew_mean      | 199      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 31838    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 7709     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 195      |\n",
      "|    ep_rew_mean      | 195      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 32667    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 7916     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 192      |\n",
      "|    ep_rew_mean      | 192      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 33671    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.627    |\n",
      "|    n_updates        | 8167     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 191      |\n",
      "|    ep_rew_mean      | 191      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 34561    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 8390     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=164.60 +/- 34.47\n",
      "Episode length: 164.60 +/- 34.47\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 165      |\n",
      "|    mean_reward      | 165      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 35000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00716  |\n",
      "|    n_updates        | 8499     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 188      |\n",
      "|    ep_rew_mean      | 188      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 35187    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 8546     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 188      |\n",
      "|    ep_rew_mean      | 188      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 35752    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 8687     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 188      |\n",
      "|    ep_rew_mean      | 188      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 36389    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 8847     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 185      |\n",
      "|    ep_rew_mean      | 185      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 36757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 8939     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 184      |\n",
      "|    ep_rew_mean      | 184      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 37343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 9085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 183      |\n",
      "|    ep_rew_mean      | 183      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 844      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 37754    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.434    |\n",
      "|    n_updates        | 9188     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 182      |\n",
      "|    ep_rew_mean      | 182      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 846      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 38278    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.055    |\n",
      "|    n_updates        | 9319     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 179      |\n",
      "|    ep_rew_mean      | 179      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 847      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 38735    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0089   |\n",
      "|    n_updates        | 9433     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 180      |\n",
      "|    ep_rew_mean      | 180      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 848      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 39349    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 9587     |\n",
      "----------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=204.40 +/- 15.11\n",
      "Episode length: 204.40 +/- 15.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 204      |\n",
      "|    mean_reward      | 204      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 40000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 9749     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 180      |\n",
      "|    ep_rew_mean      | 180      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 40058    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0632   |\n",
      "|    n_updates        | 9764     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 178      |\n",
      "|    ep_rew_mean      | 178      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 838      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 40535    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 9883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 176      |\n",
      "|    ep_rew_mean      | 176      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 41126    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0685   |\n",
      "|    n_updates        | 10031    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 174      |\n",
      "|    ep_rew_mean      | 174      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 41805    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.91     |\n",
      "|    n_updates        | 10201    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 173      |\n",
      "|    ep_rew_mean      | 173      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 42351    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 10337    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 171      |\n",
      "|    ep_rew_mean      | 171      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 42824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 10455    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 167      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 43384    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0798   |\n",
      "|    n_updates        | 10595    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 164      |\n",
      "|    ep_rew_mean      | 164      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 43763    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.959    |\n",
      "|    n_updates        | 10690    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 159      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 44167    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.506    |\n",
      "|    n_updates        | 10791    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 155      |\n",
      "|    ep_rew_mean      | 155      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 44638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0474   |\n",
      "|    n_updates        | 10909    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=262.80 +/- 31.32\n",
      "Episode length: 262.80 +/- 31.32\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 263      |\n",
      "|    mean_reward      | 263      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 45000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00958  |\n",
      "|    n_updates        | 10999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 153      |\n",
      "|    ep_rew_mean      | 153      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 45162    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 11040    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | 145      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 828      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 45433    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.58     |\n",
      "|    n_updates        | 11108    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 139      |\n",
      "|    ep_rew_mean      | 139      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 829      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 45748    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.445    |\n",
      "|    n_updates        | 11186    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 133      |\n",
      "|    ep_rew_mean      | 133      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 830      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 45975    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.482    |\n",
      "|    n_updates        | 11243    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 832      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 46623    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 11405    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 47193    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.478    |\n",
      "|    n_updates        | 11548    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 47681    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.763    |\n",
      "|    n_updates        | 11670    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 48063    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.525    |\n",
      "|    n_updates        | 11765    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 48713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00937  |\n",
      "|    n_updates        | 11928    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 841      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 49210    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0627   |\n",
      "|    n_updates        | 12052    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 841      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 49688    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.826    |\n",
      "|    n_updates        | 12171    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=139.20 +/- 7.36\n",
      "Episode length: 139.20 +/- 7.36\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 139      |\n",
      "|    mean_reward      | 139      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 50000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 12249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 50206    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 12301    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 50722    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.84     |\n",
      "|    n_updates        | 12430    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 51190    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.523    |\n",
      "|    n_updates        | 12547    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 51809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.696    |\n",
      "|    n_updates        | 12702    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 52342    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 12835    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 52841    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.656    |\n",
      "|    n_updates        | 12960    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 53305    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.662    |\n",
      "|    n_updates        | 13076    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 53681    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 13170    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 834      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 54170    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0063   |\n",
      "|    n_updates        | 13292    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 54668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00816  |\n",
      "|    n_updates        | 13416    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=127.50 +/- 4.82\n",
      "Episode length: 127.50 +/- 4.82\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 128      |\n",
      "|    mean_reward      | 128      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 55000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00608  |\n",
      "|    n_updates        | 13499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 55169    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.919    |\n",
      "|    n_updates        | 13542    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 55638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.563    |\n",
      "|    n_updates        | 13659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 833      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 56102    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.696    |\n",
      "|    n_updates        | 13775    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 835      |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 56560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.477    |\n",
      "|    n_updates        | 13889    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 836      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 57018    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.759    |\n",
      "|    n_updates        | 14004    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 57476    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.535    |\n",
      "|    n_updates        | 14118    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 839      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 57954    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00443  |\n",
      "|    n_updates        | 14238    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 840      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 58419    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 14354    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 58889    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 14472    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 844      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 59344    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 14585    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 59813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 14703    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=111.20 +/- 4.58\n",
      "Episode length: 111.20 +/- 4.58\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 111      |\n",
      "|    mean_reward      | 111      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 60000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00819  |\n",
      "|    n_updates        | 14749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 842      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 60301    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 14825    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 844      |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 60793    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.41     |\n",
      "|    n_updates        | 14948    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 845      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 61291    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 15072    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 121      |\n",
      "|    ep_rew_mean      | 121      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 846      |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 61760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00532  |\n",
      "|    n_updates        | 15189    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 847      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 62215    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00883  |\n",
      "|    n_updates        | 15303    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 848      |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 62584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.418    |\n",
      "|    n_updates        | 15395    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 63010    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 15502    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 851      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 63467    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 15616    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 852      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 63916    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00439  |\n",
      "|    n_updates        | 15728    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 115      |\n",
      "|    ep_rew_mean      | 115      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 64350    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00811  |\n",
      "|    n_updates        | 15837    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 64689    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.513    |\n",
      "|    n_updates        | 15922    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=108.30 +/- 2.10\n",
      "Episode length: 108.30 +/- 2.10\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 108      |\n",
      "|    mean_reward      | 108      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 65000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 15999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 851      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 65120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00751  |\n",
      "|    n_updates        | 16029    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 852      |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 65471    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00734  |\n",
      "|    n_updates        | 16117    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 853      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 65923    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00948  |\n",
      "|    n_updates        | 16230    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 854      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 66362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 16340    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 66720    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.375    |\n",
      "|    n_updates        | 16429    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 857      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 67179    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.386    |\n",
      "|    n_updates        | 16544    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 858      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 67651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 16662    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 859      |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 67896    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 16723    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 860      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 68263    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 16815    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 68783    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 16945    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 863      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 69283    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 17070    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 108      |\n",
      "|    ep_rew_mean      | 108      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 69706    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 17176    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=135.60 +/- 12.11\n",
      "Episode length: 135.60 +/- 12.11\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 136      |\n",
      "|    mean_reward      | 136      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 70000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 17249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 70247    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 17311    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 109      |\n",
      "|    ep_rew_mean      | 109      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 864      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 70762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.34     |\n",
      "|    n_updates        | 17440    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 110      |\n",
      "|    ep_rew_mean      | 110      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 865      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 71260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 17564    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 867      |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 71873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 17718    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 72431    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.615    |\n",
      "|    n_updates        | 17857    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 72904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 17975    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 73286    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.91     |\n",
      "|    n_updates        | 18071    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 111      |\n",
      "|    ep_rew_mean      | 111      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 872      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 73725    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.545    |\n",
      "|    n_updates        | 18181    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 74165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 18291    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 74629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.948    |\n",
      "|    n_updates        | 18407    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=75000, episode_reward=104.90 +/- 2.81\n",
      "Episode length: 104.90 +/- 2.81\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 105      |\n",
      "|    mean_reward      | 105      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 75000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 18499    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 112      |\n",
      "|    ep_rew_mean      | 112      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 869      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 75096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 18523    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 113      |\n",
      "|    ep_rew_mean      | 113      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 870      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 75604    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00519  |\n",
      "|    n_updates        | 18650    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 114      |\n",
      "|    ep_rew_mean      | 114      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 871      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 76094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 18773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 116      |\n",
      "|    ep_rew_mean      | 116      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 76678    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 18919    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 874      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 77181    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 19045    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 117      |\n",
      "|    ep_rew_mean      | 117      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 875      |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 77665    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00904  |\n",
      "|    n_updates        | 19166    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 118      |\n",
      "|    ep_rew_mean      | 118      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 877      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 78207    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 19301    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 120      |\n",
      "|    ep_rew_mean      | 120      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 78705    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 19426    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 79073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 19518    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 119      |\n",
      "|    ep_rew_mean      | 119      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 79570    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00834  |\n",
      "|    n_updates        | 19642    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=142.50 +/- 9.55\n",
      "Episode length: 142.50 +/- 9.55\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 142      |\n",
      "|    mean_reward      | 142      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 80000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 19749    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 122      |\n",
      "|    ep_rew_mean      | 122      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 878      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 80088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.88     |\n",
      "|    n_updates        | 19771    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 123      |\n",
      "|    ep_rew_mean      | 123      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 80564    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 19890    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 124      |\n",
      "|    ep_rew_mean      | 124      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 81137    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 20034    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 125      |\n",
      "|    ep_rew_mean      | 125      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 81780    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00853  |\n",
      "|    n_updates        | 20194    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 126      |\n",
      "|    ep_rew_mean      | 126      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 82325    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 20331    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 127      |\n",
      "|    ep_rew_mean      | 127      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 82898    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0093   |\n",
      "|    n_updates        | 20474    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 885      |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 83637    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 20659    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 84400    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0839   |\n",
      "|    n_updates        | 20849    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=224.50 +/- 62.16\n",
      "Episode length: 224.50 +/- 62.16\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 224      |\n",
      "|    mean_reward      | 224      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 85000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 20999    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 879      |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 85042    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 21010    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 85503    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 21125    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 85968    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.392    |\n",
      "|    n_updates        | 21241    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 881      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 86412    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00997  |\n",
      "|    n_updates        | 21352    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 131      |\n",
      "|    ep_rew_mean      | 131      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 882      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 86802    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0604   |\n",
      "|    n_updates        | 21450    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 129      |\n",
      "|    ep_rew_mean      | 129      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 883      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 87043    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0899   |\n",
      "|    n_updates        | 21510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 128      |\n",
      "|    ep_rew_mean      | 128      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 884      |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 87475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 21618    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 130      |\n",
      "|    ep_rew_mean      | 130      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 886      |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 88094    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 21773    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 132      |\n",
      "|    ep_rew_mean      | 132      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 88850    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00614  |\n",
      "|    n_updates        | 21962    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 133      |\n",
      "|    ep_rew_mean      | 133      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 889      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 89416    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 22103    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=117.50 +/- 5.52\n",
      "Episode length: 117.50 +/- 5.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 118      |\n",
      "|    mean_reward      | 118      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 90000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0304   |\n",
      "|    n_updates        | 22249    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | 135      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 888      |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 90161    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 22290    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 141      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 891      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 91242    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00709  |\n",
      "|    n_updates        | 22560    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 143      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 91934    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 22733    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | 145      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 92721    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.964    |\n",
      "|    n_updates        | 22930    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | 145      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 896      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 93229    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 23057    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | 148      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 898      |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 93920    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 23229    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | 152      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 900      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 94766    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00801  |\n",
      "|    n_updates        | 23441    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=331.10 +/- 59.95\n",
      "Episode length: 331.10 +/- 59.95\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 331      |\n",
      "|    mean_reward      | 331      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 95000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0059   |\n",
      "|    n_updates        | 23499    |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 155      |\n",
      "|    ep_rew_mean      | 155      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 893      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 95608    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00743  |\n",
      "|    n_updates        | 23651    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 161      |\n",
      "|    ep_rew_mean      | 161      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 895      |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 96628    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.623    |\n",
      "|    n_updates        | 23906    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 163      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 897      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 97398    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00726  |\n",
      "|    n_updates        | 24099    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 162      |\n",
      "|    ep_rew_mean      | 162      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 899      |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 97988    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00927  |\n",
      "|    n_updates        | 24246    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 167      |\n",
      "|    ep_rew_mean      | 167      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 901      |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 99044    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 24510    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 166      |\n",
      "|    ep_rew_mean      | 166      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 902      |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 99537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 24634    |\n",
      "----------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=133.00 +/- 3.52\n",
      "Episode length: 133.00 +/- 3.52\n",
      "----------------------------------\n",
      "| eval/               |          |\n",
      "|    mean_ep_length   | 133      |\n",
      "|    mean_reward      | 133      |\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    total_timesteps  | 100000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.001    |\n",
      "|    loss             | 0.00503  |\n",
      "|    n_updates        | 24749    |\n",
      "----------------------------------\n",
      "[DQN] 최종 평가: mean_reward=129.85, std=3.31\n",
      "\n",
      "==== 최종 요약 (20-episode 평균 리워드 기준) ====\n",
      "SAC : mean=500.00, std=0.00\n",
      "PPO : mean=500.00, std=0.00\n",
      "DQN : mean=129.85, std=3.31\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import SAC, PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 1) 연속 행동 CartPole 래퍼\n",
    "# -------------------------------\n",
    "class ContinuousCartPoleEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    CartPole-v1 위에 얹는 연속 행동 래퍼.\n",
    "    - 원래 CartPole은 Discrete(2) 행동 공간 (왼/오른쪽)\n",
    "    - 여기서는 Box(-1, 1) 연속 행동을 받아 0/1 로 threshold 하여 전달\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 50}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.render_mode = render_mode\n",
    "        self._env = gym.make(\"CartPole-v1\", render_mode=render_mode)\n",
    "\n",
    "        # 관측 공간은 그대로\n",
    "        self.observation_space = self._env.observation_space\n",
    "        # 행동 공간을 연속 [-1, 1] 로 정의\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0, high=1.0, shape=(1,), dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self, seed: int | None = None, options: dict | None = None):\n",
    "        obs, info = self._env.reset(seed=seed, options=options)\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action: np.ndarray):\n",
    "        # 연속 action[0] 을 0/1 로 매핑\n",
    "        discrete_action = 1 if action[0] > 0.0 else 0\n",
    "        obs, reward, terminated, truncated, info = self._env.step(discrete_action)\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        return self._env.render()\n",
    "\n",
    "    def close(self):\n",
    "        self._env.close()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2) 공통 학습 + 평가 유틸\n",
    "# -------------------------------\n",
    "def train_with_eval(\n",
    "    algo_name: str,\n",
    "    model_cls,\n",
    "    make_env_fn: Callable[[], gym.Env],\n",
    "    total_timesteps: int,\n",
    "    log_dir: str,\n",
    "    **model_kwargs,\n",
    ") -> Tuple[object, Tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    공통 학습 함수\n",
    "    - algo_name: \"sac\"/\"ppo\"/\"dqn\" 등\n",
    "    - model_cls: SAC / PPO / DQN 클래스\n",
    "    - make_env_fn: gym.Env 를 하나 생성하는 함수\n",
    "    - total_timesteps: 학습 스텝 수\n",
    "    - log_dir: 로그/모델 저장 디렉토리\n",
    "    \"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    # 벡터화된 학습 환경 (1개 env)\n",
    "    train_env = make_vec_env(\n",
    "        make_env_fn,\n",
    "        n_envs=1,\n",
    "        monitor_dir=log_dir,  # Monitor로 episode reward/length 기록\n",
    "    )\n",
    "\n",
    "    # 평가용 환경 (VecEnv 아님, 단일 env)\n",
    "    eval_env = Monitor(make_env_fn(), log_dir)\n",
    "\n",
    "    # 주기적으로 평가, 결과는 evaluations.npz로 저장\n",
    "    eval_callback = EvalCallback(\n",
    "        eval_env,\n",
    "        best_model_save_path=log_dir,\n",
    "        log_path=log_dir,\n",
    "        eval_freq=5_000,\n",
    "        n_eval_episodes=10,\n",
    "        deterministic=True,\n",
    "        render=False,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n==== 학습 시작: {algo_name.upper()} ====\")\n",
    "    model = model_cls(\n",
    "        \"MlpPolicy\",\n",
    "        train_env,\n",
    "        verbose=1,\n",
    "        **model_kwargs,\n",
    "    )\n",
    "    model.learn(total_timesteps=total_timesteps, callback=eval_callback)\n",
    "\n",
    "    # 최종 정책 평가\n",
    "    mean_reward, std_reward = evaluate_policy(\n",
    "        model, eval_env, n_eval_episodes=20, deterministic=True\n",
    "    )\n",
    "    print(\n",
    "        f\"[{algo_name.upper()}] 최종 평가: \"\n",
    "        f\"mean_reward={mean_reward:.2f}, std={std_reward:.2f}\"\n",
    "    )\n",
    "\n",
    "    eval_env.close()\n",
    "    train_env.close()\n",
    "\n",
    "    return model, (mean_reward, std_reward)\n",
    "\n",
    "\n",
    "def plot_learning_curves(experiments: list[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    EvalCallback이 저장한 evaluations.npz 로부터\n",
    "    timestep-mean_reward 곡선 플롯\n",
    "    experiments: [(label, log_dir), ...]\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    for label, log_dir in experiments:\n",
    "        eval_path = os.path.join(log_dir, \"evaluations.npz\")\n",
    "        if not os.path.exists(eval_path):\n",
    "            print(f\"[경고] {label} 에 대한 {eval_path} 파일이 없습니다. 건너뜀.\")\n",
    "            continue\n",
    "\n",
    "        data = np.load(eval_path)\n",
    "        timesteps = data[\"timesteps\"]  # shape: (n_eval,)\n",
    "        results = data[\"results\"]      # shape: (n_eval, n_eval_episodes)\n",
    "        mean_rewards = results.mean(axis=1)\n",
    "\n",
    "        plt.plot(timesteps, mean_rewards, label=label)\n",
    "\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Mean evaluation reward\")\n",
    "    plt.title(\"CartPole: SAC vs PPO vs DQN (mean eval reward)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 3) main: SAC vs PPO vs DQN\n",
    "# -------------------------------\n",
    "def main():\n",
    "    TOTAL_TIMESTEPS = 100_000  # 과제 규모에 맞게 조정 가능\n",
    "\n",
    "    # 1) SAC: 연속 행동 CartPole 래퍼 사용\n",
    "    sac_log_dir = \"./logs/sac_cartpole\"\n",
    "    sac_model, sac_eval = train_with_eval(\n",
    "        algo_name=\"sac\",\n",
    "        model_cls=SAC,\n",
    "        make_env_fn=lambda: ContinuousCartPoleEnv(),\n",
    "        total_timesteps=TOTAL_TIMESTEPS,\n",
    "        log_dir=sac_log_dir,\n",
    "        # 필요시 하이퍼파라미터 조정\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        buffer_size=100_000,\n",
    "        batch_size=64,\n",
    "        tau=0.005,\n",
    "        train_freq=1,\n",
    "        gradient_steps=1,\n",
    "    )\n",
    "\n",
    "    # 2) PPO: 기본 CartPole (이산 행동)\n",
    "    ppo_log_dir = \"./logs/ppo_cartpole\"\n",
    "    ppo_model, ppo_eval = train_with_eval(\n",
    "        algo_name=\"ppo\",\n",
    "        model_cls=PPO,\n",
    "        make_env_fn=lambda: gym.make(\"CartPole-v1\"),\n",
    "        total_timesteps=TOTAL_TIMESTEPS,\n",
    "        log_dir=ppo_log_dir,\n",
    "        gamma=0.99,\n",
    "        n_steps=2048,\n",
    "        learning_rate=3e-4,\n",
    "        batch_size=64,\n",
    "        ent_coef=0.0,\n",
    "    )\n",
    "\n",
    "    # 3) DQN: 기본 CartPole (이산 행동)\n",
    "    dqn_log_dir = \"./logs/dqn_cartpole\"\n",
    "    dqn_model, dqn_eval = train_with_eval(\n",
    "        algo_name=\"dqn\",\n",
    "        model_cls=DQN,\n",
    "        make_env_fn=lambda: gym.make(\"CartPole-v1\"),\n",
    "        total_timesteps=TOTAL_TIMESTEPS,\n",
    "        log_dir=dqn_log_dir,\n",
    "        learning_rate=1e-3,\n",
    "        buffer_size=50_000,\n",
    "        learning_starts=1_000,\n",
    "        batch_size=64,\n",
    "        tau=1.0,\n",
    "        gamma=0.99,\n",
    "        train_freq=4,\n",
    "        target_update_interval=1_000,\n",
    "    )\n",
    "\n",
    "    print(\"\\n==== 최종 요약 (20-episode 평균 리워드 기준) ====\")\n",
    "    print(f\"SAC : mean={sac_eval[0]:.2f}, std={sac_eval[1]:.2f}\")\n",
    "    print(f\"PPO : mean={ppo_eval[0]:.2f}, std={ppo_eval[1]:.2f}\")\n",
    "    print(f\"DQN : mean={dqn_eval[0]:.2f}, std={dqn_eval[1]:.2f}\")\n",
    "\n",
    "    # 학습 과정 비교 플롯\n",
    "    experiments = [\n",
    "        (\"SAC (cont CartPole)\", sac_log_dir),\n",
    "        (\"PPO\", ppo_log_dir),\n",
    "        (\"DQN\", dqn_log_dir),\n",
    "    ]\n",
    "    plot_learning_curves(experiments)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e609e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vissim_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
